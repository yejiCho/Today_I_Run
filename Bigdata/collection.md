# 1. 빅데이터 이해하기

```
3V =데이터의 크기(Volume), 데이터입출력 속도(Velocity), 데이터 종류의 다양성(Variety)
+
2V = 진실성(Veracity) , 시각화(Visualization)
+
1V = 가치(Value)
```

## 빅데이터 구현 기술

```
빅데이터 아키텍처는 역할별로 수집, 적재,처리 및 탐색, 분석 및 응용이라는 6개의 레이어로 나눌 수 있다
```
|단계|역할|활용 기슐||
|-----|-------|------------|-------|
|수집|내,외부 데이터 수집<br/>내,외부 데이터 통합|Crawling,FTP, OpenAPI|전처리|
|적재|대용량/실시간 데이터 처리<br/>분산 파일 시스템 저장|No-SQL, Memory Cached, Distributed File|전처리|
|처리|데이터 선택,변환,통합,축소<br/>데이터 워크플로 및 자동화|Structed Processing<br/>Unstructured Processing<br/>Workflow,Scheduler|전처리,후처리|
|탐색|대화형 데이터 질의<br/>탐색적 Ad-Hoc분석|SQL Like<br/>Distributed Programming<br/>Exploration Visualization|후처리|
|분석|빅데이터 마트 구성<br/>통계,분석,고급 분석|Data Mining<br/>ML<br/>Analysis Visualization|후처리|
|응용|보고서 및 시각화<br/>분석 정보 제공|Data Export/Import<br/>Reporting<br/>Business Visualization|활용|

```
구축 순서도 통상 수집 -> 적재 -> 처리 및 탐색 -> 분석 및 응용 순으로 진행되며, '처리 및 탐색'과 '분석 및 응용' 단계는 필요 시 반복 진행하면서 데이터의 품질과 분석 수준을 향상 시킨다.
```

![bigdata_수집환경](https://github.com/yejiCho/Today_I_Run/blob/master/Bigdata/img/%EC%88%98%EC%A7%91%ED%99%98%EA%B2%BD.jpg?raw=true)

### 빅데이터 수집 개요

```
빅데이터 시스템의 구축은 수집에서 부터 시작된다. 빅데이터 프로젝트 에서는 여러 공정 단계가 있는데, 그 중 수집이 전체 공정 과정의 절반 이상을 차지한다.
```
### 빅데이터 수집에 활용할 기술

#### Flume
```
플럼(Flume)은 빅데이터를 수집할 때 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어이다.
데이터를 원천으로부터 수집할 때 통신 프로토콜, 메시지 포맷, 발생주기,
데이터 크기 등으로 많은 고민을 하게 되는데 플럼은 이러한 고민을 쉽게 해결할 수 있는 기능과 아키텍처를 제공한다.
```

- 플럼 활용방안

```
플럼은 스마트카에서 발생하는 로그를 직접 수집하는 역할을 담당한다.
발생하는 로그 유형에 따라 두 가지 플럼 에이젼트를 구성할 것이다.

첫번째로 100대의 스마트카에 대한 상태 정보 로그 파일이 로그 시뮬레이터를 통해 매일 생성된다. 이렇게 만들어진 상태 정보 파일을 플럼 에이전트가 일 단위로 수집해서 하둡에 적재하고 향후 대규모 배치 분석에 활용

두번째로 스마트카 운전자 100명의 운행 정보를 실시간으로 기록하는 로그 파일이 로그 시뮬레이터에 의해 만들어지는데, 이때 발생과 동시에 플럼 에이전트가 수집해서 카프카에 전송한다.
```

- 플럼의 기본 요소

![Flume_component](https://github.com/yejiCho/Today_I_Run/blob/master/Bigdata/img/Flume_component.jpg?raw=true)



#### Kafka

```

Kafka는 MOM(Message Oriented Middleware)소프트웨어 중 하나로서 대규모로 발생하는 메세지성 데이터를 비동기 방식으로 중계하는 역할
원천 시스템으로부터 대규모 트랜잭션 데이터가 발생했을 때 중간에 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 중간 시스템이 필요한데, 카프카가 그와 관련된 강력한 기능과 아키텍쳐 제공
```



- 카프카의 기본요소

   |  Broker  | 카프카의 서비스 인스턴스로서, 다수의 Broker를 클러스터로 구성하고 Topic이 생성되는 물리적 서버 |
   | :------: | ------------------------------------------------------------ |
   |  Topic   | Broker에서 데이터의 발행/소비 처리를 위한 저장소             |
   | Provider | Broker의 특정 Topic에 데이터를 전송(발행)하는 역할로서 애플리케이션에서 카프카 라이브러리를 이용해 구형 |
   | Consumer | Broker의 특정Topic에서 데이터를 수신(소비)하는 역할로서 애플리케이션에서 카프카 라이브러리를 이용해 구현 |

  

- 카프카 활용방안

  ```
  플럼이 아주 빠르게 발생하는 데이터를 실시간으로 수집하게 되면 이를 최종 목적지에 전달하기 전 중간에서
  안정적인 버퍼링 처리가 필요해서이다.
  스마트카 운전자의 운행 정보는 100명이 1초 간격으로 동시에 발생시키는, 속도가 매우 빠른 데이터로서 플럼 입장에서는 데이터 수집이 부담스럽다.
  이때! 카프카와 같은 분산 환경의 대규모 중간 저장소가 완충 역할을 함으로써 안정적인 수집 아키텍처를 구성할 수 있다.
  
  ```

