# 수집 파일럿 실행 1단계 - 수집 아키텍처

## 수집 요구사항

- 요구사항1 : 차량의 다양한 장치로 부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검

- 요구사항2 : 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴 분석

  

## 요구사항 구체화 및 분석

| 수집 요구사항 구체화                                         | 분석 및 해결 방안                                            |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1. 스마트카로부터 로그 파일들이 주기적으로 발생              | 플럼을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집    |
| 2. 스마트카의 배치 로그 파일 이벤트를 감지                   | 플럼의 Source 컴포넌트 중 SpoolDir를 이용해<br/> 주기적인 로그 파일 발생 이벤트를 감지 |
| 3. 스마트카의 실시간 로그 발생 이벤트 감지                   | 플럼의 Source 컴포넌트 중 Exec-Tail을 이용해<br/> 특정 로그 파일에서 로그 생성 이벤트 감지 |
| 4. 스마트카가 만들어내는 로그 데이터에<br/> 가비지 데이터가 있을 수 있다. | 플럼의 Interceptor를 이용해 정상 패턴의 데이터만 필터링      |
| 5. 수집 도중 장애가 발생해도 데이터를 안전하게<br/> 보관 및 재처리 할 수 있어야한다. | 플럼의 메모리 Channel 및 카프카 Broker 사용으로 <br/> 로컬 디스크의 파일시스템에 수집 데이터를 임시 저장 |
| 6. 스마트카의 실시간 로그 파일은 비동기 처리로<br/> 빠른 수집처리를 해야한다. | 플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해<br/> 카프카 Topic에 비동기 전송 |



```
파일럿 프로젝트의 수집 아키텍처는 원천 데이터의 발생 유형에 따라 크게 2개의 레이어로 나눌 수 있다.
대용량 로그 파일을 주기적으로 수집해서 표준 입출력 로거를 보여주는 플럼 에이전트 1 레이어
실시간으로 발생하는 로그를 라인 단위로 수집해 카프카의 Topic에 전송하는 플럼 에이전트 2 레이어
```

### 로그 시뮬레이터

스마트카의 상태 정보와 운전자의 운행 정보 로그를 가상으로 만드는 자바 로그 발생기

1. 스마트카 상태 정보 : 100대 스마트카 장치들의 상태 정보를 3초 간격으로 발생시키며, 1일 100MB의 로그 파일이 만들어진다.

6. 스마트카 운전자 운행 정보: 100명의 스마트카 운전자들의 운행 정보를 실시간으로 발생시키며, 발생된 하나의 운행 정보 로그는 4KB 미만이다. 동시에 최대 400KB 용량으로 실시간 데이터가 발생된다.

### 플럼 에이전트1

스마트카 상태 정보를 기록한 로그 파일을 일별로 수집하기 위한 배치성 플럼 에이전트

2. SpoolDir Source : 약속된 로그 발생 디렉터리를 모니터링하다가 정의된 로그 파일 발생 시 해당 파일의 내용을 읽어서 수집하는 기능 제공
3. Memory Channel : SpoolDir Source로부터 수집된 데이터를 메모리 Channel에 중간 적재한다. 버퍼링 기능을 제공하며, Sink와 연결되어 트랜잭션 처리를 지원
4. Logger Sink : Channel로 부터 읽어들인 데이터를 플럼의 표준 로그 파일로 출력하게 된다.

### 플럼 에이전트2

스마트카 운전자의 운행 정보를 실시간으로 수집하기 위한 실시간성 플럼 에이전트

7. Exec-Tail Source : 로그가 쌓이고 있는 파일에 Tail 파이프라인을 이용해 실시간으로 데이터를 수집하는 기능 제공
8. Memory Channel : Exec-Tail Source로 부터 수집된 데이터를 메모리 Channel에 버퍼링 처리를 하면서 임시 적재
9. Kafka Sink : Channel로 부터 읽어들인 데이터를 카프카 Broker의 특정 토픽에 비동기 방식으로 전송하는 Provider 역할 수행

### 기타

플럼이 수집한 로그 데이터를 임시 출력 및 저장

5. Flume Stdout : 플럼의 Logger-Sink를 통해 표준 출력 로그가 출력

10. Kafka Topic : 플럼의 Kafka-Sink는 수집된 실시간 로그를 임시 적재